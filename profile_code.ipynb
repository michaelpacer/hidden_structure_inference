{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "\n",
    "p =pstats.Stats('results/cprofile4.txt')\n",
    "p.strip_dirs().sort_stats(-1).print_stats()\n",
    "\n",
    "p.sort_stats('cumtime').print_stats(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 0.089729 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: logposterior_from_loglik_logsparseprior at line 26\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    26                                               @profile\n",
      "    27                                               def logposterior_from_loglik_logsparseprior(self,loglik,sparsity=.5):\n",
      "    28         4        89188  22297.0     99.4          logp = log_sparse_graphset_prior(self.graphs,sparsity=sparsity)\n",
      "    29         4           12      3.0      0.0          unnormed_logposterior = loglik+logp\n",
      "    30         4            3      0.8      0.0          try: \n",
      "    31                                                       # np.seterr(all='raise')\n",
      "    32         4          276     69.0      0.3              unnormed_logposterior - logsumexp(unnormed_logposterior)\n",
      "    33                                                       # np.seterr(over='raise')\n",
      "    34                                                   except RuntimeWarning: \n",
      "    35                                                       import ipdb; ipdb.set_trace()\n",
      "    36                                                   \n",
      "    37         4          250     62.5      0.3          return unnormed_logposterior - logsumexp(unnormed_logposterior)\n",
      "\n",
      "Total time: 5278.38 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: p_graph_given_d at line 39\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    39                                               @profile\n",
      "    40                                               def p_graph_given_d(self,graphs,options):\n",
      "    41                                                   # sets a catch for all numerical warnings to be treated as errors\n",
      "    42                                                   # np.seterr(all='raise')\n",
      "    43                                                   # np.seterr(under='raise')\n",
      "    44         4           68     17.0      0.0          np.seterr(over='raise')\n",
      "    45                                                   \"\"\"\n",
      "    46                                                   options includes \n",
      "    47                                                   sparsity: the sparsity argument for the prior \n",
      "    48                                                   param_sample_size: the number of parameters to be sampled\n",
      "    49                                                   stigma_sample_size: the number of internal states to be sampled\n",
      "    50                                                   data_sets: the different data_sets to be evaluated as likelihoods\n",
      "    51                                                   data_p: the probability of each data_set in data_sets\n",
      "    52                                                   num_data_samps: number of samples of observed data to be considered in the liklihood\n",
      "    53                                                   \"\"\"\n",
      "    54         4            6      1.5      0.0          self.graphs = graphs\n",
      "    55         4            5      1.2      0.0          self.max_graph = self.graphs[0]\n",
      "    56         4            5      1.2      0.0          self.options = options\n",
      "    57         4            5      1.2      0.0          num_graphs = len(graphs)\n",
      "    58                                                   # loglikelihood = np.empty(len(self.graphs))\n",
      "    59         4            5      1.2      0.0          num_params= options[\"param_sample_size\"]\n",
      "    60                                           \n",
      "    61                                                   # generate 1 complete graph with many data structures shared beneath it\n",
      "    62                                           \n",
      "    63                                           \n",
      "    64         4          254     63.5      0.0          max_graph_params = GraphParams.from_networkx(self.max_graph)\n",
      "    65                                                   \n",
      "    66         4        21637   5409.2      0.0          self.param_list = [max_graph_params.sample() for x in range(num_params)]\n",
      "    67                                           \n",
      "    68                                                   # loglikelihood_by_param = np.array(Parallel(n_jobs = -2, \n",
      "    69                                                   #     backend = \"multiprocessing\", verbose = 10)(\n",
      "    70                                                   #     delayed(self._helper_subgraph_loglik)(\n",
      "    71                                                   #         max_graph_params.from_dict(params)) for params in self.param_list))\n",
      "    72                                                   \n",
      "    73                                                   # loglikelihood_by_param = np.array(Parallel(n_jobs = -1, \n",
      "    74                                                   #     backend = \"multiprocessing\", verbose = 20)(\n",
      "    75                                                   #     delayed(self.subgraph_cross_entropy)(\n",
      "    76                                                   #         max_graph_params.from_dict(params)) for params in self.param_list))\n",
      "    77                                           \n",
      "    78         4            9      2.2      0.0          loglikelihood_by_param = np.array([self.subgraph_cross_entropy(max_graph_params.from_dict(params)) \n",
      "    79         4   5278263449 1319565862.2    100.0              for params in self.param_list])\n",
      "    80                                                   \n",
      "    81         4         2485    621.2      0.0          loglikelihood = logmeanexp(loglikelihood_by_param,axis=0)\n",
      "    82                                                   \n",
      "    83         4            9      2.2      0.0          sparsity = options[\"sparsity\"]\n",
      "    84         4        89789  22447.2      0.0          logposterior = self.logposterior_from_loglik_logsparseprior(loglikelihood,sparsity=sparsity)\n",
      "    85                                           \n",
      "    86         4           24      6.0      0.0          return graphs,np.exp(logposterior),loglikelihood,self.options,self.param_list\n",
      "\n",
      "Total time: 5278.25 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: subgraph_cross_entropy at line 91\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    91                                               @profile\n",
      "    92                                           \n",
      "    93                                               def subgraph_cross_entropy(self,max_graph_params):\n",
      "    94                                                   n = self.options[\"num_data_samps\"]\n",
      "    95                                                   q = np.array(self.options[\"data_probs\"])\n",
      "    96                                                   δ = np.array(self.options[\"data_sets\"])\n",
      "    97                                           \n",
      "    98                                                   gs_out = GraphStructure.from_networkx(sub_graph_from_edge_type(self.max_graph,\n",
      "    99                                                       edge_types=[\"observed\"]))\n",
      "   100                                                   gp_out = max_graph_params.subgraph_copy(gs_out.edges)\n",
      "   101                                           \n",
      "   102                                                   # note that q*loglik_from_aux_data should be vector)\n",
      "   103                                                   return np.array([n*np.dot(q,self.approx_loglik_from_hidden_states(δ,graph,max_graph_params,gs_out,gp_out)) for graph in self.graphs])\n",
      "\n",
      "Total time: 0.667803 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: gen_iter_simulations_first_only at line 114\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   114                                           \n",
      "\n",
      "Total time: 5248.04 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: approx_loglik_from_hidden_states at line 120\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   120                                           \n",
      "\n",
      "Total time: 3702.64 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: loglik_with_hidden_states at line 153\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   153                                                   # if the cause does occur it happens at some time other than infinity\n",
      "\n",
      "Total time: 1356.39 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: one_edge_loglik at line 160\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   160                                                               exp_val = np.exp(-r*(T-cause_time))\n",
      "\n",
      "Total time: 0 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: loglik_from_aux_data at line 210\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   210                                           \n",
      "   211                                                   # return self.aux_data_monte_carlo_loglik(gs_in,gp_in,gs_out,gp_out,\n",
      "   212                                                   #     stigma_sample_size,options=options)\n",
      "   213                                           \n",
      "   214                                           \n",
      "   215                                               def gen_simulations(self,gs_in,gp_in,M):\n",
      "   216                                                   # builds simulation object and samples it returning an M lengthed list\n",
      "   217                                                   inner_simul = InnerGraphSimulation(gs_in,gp_in)\n",
      "   218                                                   return inner_simul.sample(M)\n",
      "\n",
      "Total time: 0 s\n",
      "File: /Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\n",
      "Function: approx_likelihood_from_aux at line 215\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   215                                               def gen_simulations(self,gs_in,gp_in,M):\n",
      "   216                                                   # builds simulation object and samples it returning an M lengthed list\n",
      "   217                                                   inner_simul = InnerGraphSimulation(gs_in,gp_in)\n",
      "   218                                                   return inner_simul.sample(M)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstats = line_profiler.load_stats(\"run_simulation.py.lprof\")\n",
    "line_profiler.show_text(lstats.timings, lstats.unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_line_profiler.LineStats at 0x1103d3a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from lib.graph_local_classes import GraphStructure, GraphParams, InnerGraphSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from lib.graph_enumerator import generate_graphs\n",
    "from lib.node_semantics import Node_Name_Rule, Edge_Semantics_Rule\n",
    "from lib import config, result_config\n",
    "from lib.likelihood_calculations_shared_params import Inference\n",
    "from lib.utils import filename_utility\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_iter = generate_graphs(**config.generator_dictionary)\n",
    "graphs = list(graph_iter)\n",
    "for graph in graphs:\n",
    "    Node_Name_Rule.graph_semantics_apply(graph,config.node_semantics)\n",
    "    Edge_Semantics_Rule.graph_semantics_apply(graph,config.edge_semantics)\n",
    "\n",
    "inference_obj = Inference()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x1059260c0, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x1059260c0, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'BA052A8EDF8E4736A9922042F96BEA97']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'BA052A8EDF8E4736A9922042F96BEA97'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-5-d75596b1a809>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>\n        self.user_global_ns = {'Edge_Semantics_Rule': <class 'lib.node_semantics.Edge_Semantics_Rule'>, 'GraphParams': <class 'lib.graph_local_classes.GraphParams'>, 'GraphStructure': <class 'lib.graph_local_classes.GraphStructure'>, 'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_ipython().magic('autoreload 2')\", 'import networkx as nx\\nimport numpy as np\\nfrom li...GraphStructure, GraphParams, InnerGraphSimulation', '\\nfrom lib.graph_enumerator import generate_graph...rom lib.utils import filename_utility\\nimport time', 'graph_iter = generate_graphs(**config.generator_...nfig.edge_semantics)\\n\\ninference_obj = Inference()', 'result_graphs, result_posterior, result_loglik, ...erence_obj.p_graph_given_d(graphs,config.options)'], 'Inference': <class 'lib.likelihood_calculations_shared_params.Inference'>, 'InnerGraphSimulation': <class 'lib.graph_local_classes.InnerGraphSimulation'>, 'Node_Name_Rule': <class 'lib.node_semantics.Node_Name_Rule'>, 'Out': {}, '_': '', '__': '', ...}\n        self.user_ns = {'Edge_Semantics_Rule': <class 'lib.node_semantics.Edge_Semantics_Rule'>, 'GraphParams': <class 'lib.graph_local_classes.GraphParams'>, 'GraphStructure': <class 'lib.graph_local_classes.GraphStructure'>, 'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_ipython().magic('autoreload 2')\", 'import networkx as nx\\nimport numpy as np\\nfrom li...GraphStructure, GraphParams, InnerGraphSimulation', '\\nfrom lib.graph_enumerator import generate_graph...rom lib.utils import filename_utility\\nimport time', 'graph_iter = generate_graphs(**config.generator_...nfig.edge_semantics)\\n\\ninference_obj = Inference()', 'result_graphs, result_posterior, result_loglik, ...erence_obj.p_graph_given_d(graphs,config.options)'], 'Inference': <class 'lib.likelihood_calculations_shared_params.Inference'>, 'InnerGraphSimulation': <class 'lib.graph_local_classes.InnerGraphSimulation'>, 'Node_Name_Rule': <class 'lib.node_semantics.Node_Name_Rule'>, 'Out': {}, '_': '', '__': '', ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/<ipython-input-5-d75596b1a809> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 result_graphs, result_posterior, result_loglik, result_dict = inference_obj.p_graph_given_d(graphs,config.options)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in p_graph_given_d(self=<lib.likelihood_calculations_shared_params.Inference object>, graphs=[<networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, ...], options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     56             #         param_sample_size,options=options) for graph in self.graphs)\n     57             max_graph_params = GraphParams.from_networkx(self.max_graph) # fix this when you can\n     58             max_graph_params.sample()\n     59             loglikelihood_by_param[i,:] = Parallel(n_jobs=-1, backend=\"multiprocessing\")(\n     60                 delayed(self.subgraph_loglik)(graph, max_graph_params,\n---> 61                     options=options) for graph in self.graphs)\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n        self.graphs = [<networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, ...]\n     62         \n     63         loglikelihood = logmeanexp(loglikelihood_by_param,axis=0)\n     64         # import ipdb; ipdb.set_trace()\n     65         # time_vec = np.empty([len(self.graphs),2])\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Inference.p_graph_given_d.<locals>.<genexpr>>)\n    807             if pre_dispatch == \"all\" or n_jobs == 1:\n    808                 # The iterable was consumed all at once by the above for loop.\n    809                 # No need to wait for async callbacks to trigger to\n    810                 # consumption.\n    811                 self._iterating = False\n--> 812             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    813             # Make sure that we get a last message telling us we are done\n    814             elapsed_time = time.time() - self._start_time\n    815             self._print('Done %3i out of %3i | elapsed: %s finished',\n    816                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jan 12 00:21:56 2016\nPID: 83838               Python 3.5.0: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>, (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>), {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>\n        args = (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>)\n        kwargs = {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in subgraph_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, graph=<networkx.classes.digraph.DiGraph object>, max_graph_params=<lib.graph_local_classes.GraphParams object>, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     88         gp_in = max_graph_params.subgraph_copy(gs_in.edges)\n     89         gp_out = max_graph_params.subgraph_copy(gs_out.edges)\n     90 \n     91 \n     92         return self.aux_data_monte_carlo_loglik(gs_in,gp_in,gs_out,gp_out,\n---> 93             stigma_sample_size,options=options)\n        stigma_sample_size = 100\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n     94 \n     95 \n     96     def logposterior_from_loglik_logsparseprior(self,loglik,sparsity=.5):\n     97         logp = log_sparse_graphset_prior(self.graphs,sparsity=sparsity)\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in aux_data_monte_carlo_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, gs_in=<lib.graph_local_classes.GraphStructure object>, gp_in=<lib.graph_local_classes.GraphParams object>, gs_out=<lib.graph_local_classes.GraphStructure object>, gp_out=<lib.graph_local_classes.GraphParams object>, stigma_sample_size=100, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n    167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n    168 \n--> 169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n        sim_loglike = <generator object Inference.aux_data_monte_carlo_loglik.<locals>.<genexpr>>\n        stigma_sample_size = 100\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in <genexpr>(.0=<generator object InnerGraphSimulation.sample_iter_solely_first_events>)\n    162 \n    163         # get parameters for the relevant nodes to calculate the likelihood \n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n--> 167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n        stigma = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n    168 \n    169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n    170 \n    171 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in cross_entropy_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, data_sets=None, data_probs=[0.512, 0.128, 0.128, 0.032, 0.2], k=100, aux_data=array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421]), obs_dict={'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)})\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n    174         # we can compute the expected cross-entropy for those kinds of data\n--> 175         return np.sum([data_probs[i]*k*self.multi_edge_loglik(obs_data, aux_data, obs_dict) for i,obs_data in enumerate(data_sets)])\n        data_probs = [0.512, 0.128, 0.128, 0.032, 0.2]\n        k = 100\n        self.multi_edge_loglik = <bound method Inference.multi_edge_loglik of <li...ood_calculations_shared_params.Inference object>>\n        aux_data = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n        obs_dict = {'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)}\n        data_sets = None\n    176     \n    177 \n    178     def multi_edge_loglik(self, obs_data,aux_data,parameters):\n    179         # return np.sum([self.one_edge_loglik(aux_data[i+1],obs_data[i+1],parameters['psi'][i+1],parameters['r'][i+1]) for i in range(len(aux_data)-1)]) \n\nTypeError: 'NoneType' object is not iterable\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\", line 93, in subgraph_loglik\n    stigma_sample_size,options=options)\n  File \"/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\", line 169, in aux_data_monte_carlo_loglik\n    return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n  File \"/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\", line 167, in <genexpr>\n    sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n  File \"/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\", line 175, in cross_entropy_loglik\n    return np.sum([data_probs[i]*k*self.multi_edge_loglik(obs_data, aux_data, obs_dict) for i,obs_data in enumerate(data_sets)])\nTypeError: 'NoneType' object is not iterable\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 143, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jan 12 00:21:56 2016\nPID: 83838               Python 3.5.0: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>, (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>), {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>\n        args = (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>)\n        kwargs = {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in subgraph_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, graph=<networkx.classes.digraph.DiGraph object>, max_graph_params=<lib.graph_local_classes.GraphParams object>, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     88         gp_in = max_graph_params.subgraph_copy(gs_in.edges)\n     89         gp_out = max_graph_params.subgraph_copy(gs_out.edges)\n     90 \n     91 \n     92         return self.aux_data_monte_carlo_loglik(gs_in,gp_in,gs_out,gp_out,\n---> 93             stigma_sample_size,options=options)\n        stigma_sample_size = 100\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n     94 \n     95 \n     96     def logposterior_from_loglik_logsparseprior(self,loglik,sparsity=.5):\n     97         logp = log_sparse_graphset_prior(self.graphs,sparsity=sparsity)\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in aux_data_monte_carlo_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, gs_in=<lib.graph_local_classes.GraphStructure object>, gp_in=<lib.graph_local_classes.GraphParams object>, gs_out=<lib.graph_local_classes.GraphStructure object>, gp_out=<lib.graph_local_classes.GraphParams object>, stigma_sample_size=100, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n    167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n    168 \n--> 169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n        sim_loglike = <generator object Inference.aux_data_monte_carlo_loglik.<locals>.<genexpr>>\n        stigma_sample_size = 100\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in <genexpr>(.0=<generator object InnerGraphSimulation.sample_iter_solely_first_events>)\n    162 \n    163         # get parameters for the relevant nodes to calculate the likelihood \n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n--> 167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n        stigma = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n    168 \n    169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n    170 \n    171 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in cross_entropy_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, data_sets=None, data_probs=[0.512, 0.128, 0.128, 0.032, 0.2], k=100, aux_data=array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421]), obs_dict={'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)})\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n    174         # we can compute the expected cross-entropy for those kinds of data\n--> 175         return np.sum([data_probs[i]*k*self.multi_edge_loglik(obs_data, aux_data, obs_dict) for i,obs_data in enumerate(data_sets)])\n        data_probs = [0.512, 0.128, 0.128, 0.032, 0.2]\n        k = 100\n        self.multi_edge_loglik = <bound method Inference.multi_edge_loglik of <li...ood_calculations_shared_params.Inference object>>\n        aux_data = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n        obs_dict = {'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)}\n        data_sets = None\n    176     \n    177 \n    178     def multi_edge_loglik(self, obs_data,aux_data,parameters):\n    179         # return np.sum([self.one_edge_loglik(aux_data[i+1],obs_data[i+1],parameters['psi'][i+1],parameters['r'][i+1]) for i in range(len(aux_data)-1)]) \n\nTypeError: 'NoneType' object is not iterable\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jan 12 00:21:56 2016\nPID: 83838               Python 3.5.0: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>, (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>), {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>\n        args = (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>)\n        kwargs = {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in subgraph_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, graph=<networkx.classes.digraph.DiGraph object>, max_graph_params=<lib.graph_local_classes.GraphParams object>, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     88         gp_in = max_graph_params.subgraph_copy(gs_in.edges)\n     89         gp_out = max_graph_params.subgraph_copy(gs_out.edges)\n     90 \n     91 \n     92         return self.aux_data_monte_carlo_loglik(gs_in,gp_in,gs_out,gp_out,\n---> 93             stigma_sample_size,options=options)\n        stigma_sample_size = 100\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n     94 \n     95 \n     96     def logposterior_from_loglik_logsparseprior(self,loglik,sparsity=.5):\n     97         logp = log_sparse_graphset_prior(self.graphs,sparsity=sparsity)\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in aux_data_monte_carlo_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, gs_in=<lib.graph_local_classes.GraphStructure object>, gp_in=<lib.graph_local_classes.GraphParams object>, gs_out=<lib.graph_local_classes.GraphStructure object>, gp_out=<lib.graph_local_classes.GraphParams object>, stigma_sample_size=100, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n    167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n    168 \n--> 169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n        sim_loglike = <generator object Inference.aux_data_monte_carlo_loglik.<locals>.<genexpr>>\n        stigma_sample_size = 100\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in <genexpr>(.0=<generator object InnerGraphSimulation.sample_iter_solely_first_events>)\n    162 \n    163         # get parameters for the relevant nodes to calculate the likelihood \n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n--> 167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n        stigma = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n    168 \n    169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n    170 \n    171 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in cross_entropy_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, data_sets=None, data_probs=[0.512, 0.128, 0.128, 0.032, 0.2], k=100, aux_data=array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421]), obs_dict={'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)})\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n    174         # we can compute the expected cross-entropy for those kinds of data\n--> 175         return np.sum([data_probs[i]*k*self.multi_edge_loglik(obs_data, aux_data, obs_dict) for i,obs_data in enumerate(data_sets)])\n        data_probs = [0.512, 0.128, 0.128, 0.032, 0.2]\n        k = 100\n        self.multi_edge_loglik = <bound method Inference.multi_edge_loglik of <li...ood_calculations_shared_params.Inference object>>\n        aux_data = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n        obs_dict = {'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)}\n        data_sets = None\n    176     \n    177 \n    178     def multi_edge_loglik(self, obs_data,aux_data,parameters):\n    179         # return np.sum([self.one_edge_loglik(aux_data[i+1],obs_data[i+1],parameters['psi'][i+1],parameters['r'][i+1]) for i in range(len(aux_data)-1)]) \n\nTypeError: 'NoneType' object is not iterable\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d75596b1a809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_loglik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_graph_given_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\u001b[0m in \u001b[0;36mp_graph_given_d\u001b[0;34m(self, graphs, options)\u001b[0m\n\u001b[1;32m     59\u001b[0m             loglikelihood_by_param[i,:] = Parallel(n_jobs=-1, backend=\"multiprocessing\")(\n\u001b[1;32m     60\u001b[0m                 delayed(self.subgraph_loglik)(graph, max_graph_params,\n\u001b[0;32m---> 61\u001b[0;31m                     options=options) for graph in self.graphs)\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloglikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogmeanexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihood_by_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m                         \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x1059260c0, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x1059260c0, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'BA052A8EDF8E4736A9922042F96BEA97']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'BA052A8EDF8E4736A9922042F96BEA97'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-01-12T00:21:56.126715', 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'session': 'BA052A8EDF8E4736A9922042F96BEA97', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'DB2A062994394D5EBC635C43C229791A', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='result_graphs, result_posterior, result_loglik, ...rence_obj.p_graph_given_d(graphs,config.options)\\n', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-5-d75596b1a809>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x106c225d0, file \"<ipython-input-5-d75596b1a809>\", line 1>\n        self.user_global_ns = {'Edge_Semantics_Rule': <class 'lib.node_semantics.Edge_Semantics_Rule'>, 'GraphParams': <class 'lib.graph_local_classes.GraphParams'>, 'GraphStructure': <class 'lib.graph_local_classes.GraphStructure'>, 'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_ipython().magic('autoreload 2')\", 'import networkx as nx\\nimport numpy as np\\nfrom li...GraphStructure, GraphParams, InnerGraphSimulation', '\\nfrom lib.graph_enumerator import generate_graph...rom lib.utils import filename_utility\\nimport time', 'graph_iter = generate_graphs(**config.generator_...nfig.edge_semantics)\\n\\ninference_obj = Inference()', 'result_graphs, result_posterior, result_loglik, ...erence_obj.p_graph_given_d(graphs,config.options)'], 'Inference': <class 'lib.likelihood_calculations_shared_params.Inference'>, 'InnerGraphSimulation': <class 'lib.graph_local_classes.InnerGraphSimulation'>, 'Node_Name_Rule': <class 'lib.node_semantics.Node_Name_Rule'>, 'Out': {}, '_': '', '__': '', ...}\n        self.user_ns = {'Edge_Semantics_Rule': <class 'lib.node_semantics.Edge_Semantics_Rule'>, 'GraphParams': <class 'lib.graph_local_classes.GraphParams'>, 'GraphStructure': <class 'lib.graph_local_classes.GraphStructure'>, 'In': ['', \"get_ipython().magic('load_ext autoreload')\\nget_ipython().magic('autoreload 2')\", 'import networkx as nx\\nimport numpy as np\\nfrom li...GraphStructure, GraphParams, InnerGraphSimulation', '\\nfrom lib.graph_enumerator import generate_graph...rom lib.utils import filename_utility\\nimport time', 'graph_iter = generate_graphs(**config.generator_...nfig.edge_semantics)\\n\\ninference_obj = Inference()', 'result_graphs, result_posterior, result_loglik, ...erence_obj.p_graph_given_d(graphs,config.options)'], 'Inference': <class 'lib.likelihood_calculations_shared_params.Inference'>, 'InnerGraphSimulation': <class 'lib.graph_local_classes.InnerGraphSimulation'>, 'Node_Name_Rule': <class 'lib.node_semantics.Node_Name_Rule'>, 'Out': {}, '_': '', '__': '', ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/<ipython-input-5-d75596b1a809> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 result_graphs, result_posterior, result_loglik, result_dict = inference_obj.p_graph_given_d(graphs,config.options)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in p_graph_given_d(self=<lib.likelihood_calculations_shared_params.Inference object>, graphs=[<networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, ...], options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     56             #         param_sample_size,options=options) for graph in self.graphs)\n     57             max_graph_params = GraphParams.from_networkx(self.max_graph) # fix this when you can\n     58             max_graph_params.sample()\n     59             loglikelihood_by_param[i,:] = Parallel(n_jobs=-1, backend=\"multiprocessing\")(\n     60                 delayed(self.subgraph_loglik)(graph, max_graph_params,\n---> 61                     options=options) for graph in self.graphs)\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n        self.graphs = [<networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, <networkx.classes.digraph.DiGraph object>, ...]\n     62         \n     63         loglikelihood = logmeanexp(loglikelihood_by_param,axis=0)\n     64         # import ipdb; ipdb.set_trace()\n     65         # time_vec = np.empty([len(self.graphs),2])\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Inference.p_graph_given_d.<locals>.<genexpr>>)\n    807             if pre_dispatch == \"all\" or n_jobs == 1:\n    808                 # The iterable was consumed all at once by the above for loop.\n    809                 # No need to wait for async callbacks to trigger to\n    810                 # consumption.\n    811                 self._iterating = False\n--> 812             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    813             # Make sure that we get a last message telling us we are done\n    814             elapsed_time = time.time() - self._start_time\n    815             self._print('Done %3i out of %3i | elapsed: %s finished',\n    816                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jan 12 00:21:56 2016\nPID: 83838               Python 3.5.0: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>, (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>), {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <bound method Inference.subgraph_loglik of <lib....ood_calculations_shared_params.Inference object>>\n        args = (<networkx.classes.digraph.DiGraph object>, <lib.graph_local_classes.GraphParams object>)\n        kwargs = {'options': {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in subgraph_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, graph=<networkx.classes.digraph.DiGraph object>, max_graph_params=<lib.graph_local_classes.GraphParams object>, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n     88         gp_in = max_graph_params.subgraph_copy(gs_in.edges)\n     89         gp_out = max_graph_params.subgraph_copy(gs_out.edges)\n     90 \n     91 \n     92         return self.aux_data_monte_carlo_loglik(gs_in,gp_in,gs_out,gp_out,\n---> 93             stigma_sample_size,options=options)\n        stigma_sample_size = 100\n        options = {'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100}\n     94 \n     95 \n     96     def logposterior_from_loglik_logsparseprior(self,loglik,sparsity=.5):\n     97         logp = log_sparse_graphset_prior(self.graphs,sparsity=sparsity)\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in aux_data_monte_carlo_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, gs_in=<lib.graph_local_classes.GraphStructure object>, gp_in=<lib.graph_local_classes.GraphParams object>, gs_out=<lib.graph_local_classes.GraphStructure object>, gp_out=<lib.graph_local_classes.GraphParams object>, stigma_sample_size=100, options={'data_probs': [0.512, 0.128, 0.128, 0.032, 0.2], 'data_sets': None, 'max_obs_time': 4, 'num_data_samps': 100, 'param_sample_size': 2, 'scale_free_bounds': (0.001, 1000), 'sparsity': 0.5, 'stigma_sample_size': 100})\n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n    167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n    168 \n--> 169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n        sim_loglike = <generator object Inference.aux_data_monte_carlo_loglik.<locals>.<genexpr>>\n        stigma_sample_size = 100\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in <genexpr>(.0=<generator object InnerGraphSimulation.sample_iter_solely_first_events>)\n    162 \n    163         # get parameters for the relevant nodes to calculate the likelihood \n    164         obs_dict = gp_out.to_dict()\n    165         \n    166         # build generator for the simulated log_likelihood for a given parameter set\n--> 167         sim_loglike = (self.cross_entropy_loglik(data_sets, data_probs, num_data_samps, stigma, obs_dict) for stigma in inner_samp)\n        stigma = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n    168 \n    169         return logmeanexp(np.fromiter(sim_loglike,dtype=np.float,count=stigma_sample_size))\n    170 \n    171 \n\n...........................................................................\n/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py in cross_entropy_loglik(self=<lib.likelihood_calculations_shared_params.Inference object>, data_sets=None, data_probs=[0.512, 0.128, 0.128, 0.032, 0.2], k=100, aux_data=array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421]), obs_dict={'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)})\n    170 \n    171 \n    172     def cross_entropy_loglik(self, data_sets,data_probs, k , aux_data, obs_dict):\n    173         # for a finite set of known kinds of data with known probs\n    174         # we can compute the expected cross-entropy for those kinds of data\n--> 175         return np.sum([data_probs[i]*k*self.multi_edge_loglik(obs_data, aux_data, obs_dict) for i,obs_data in enumerate(data_sets)])\n        data_probs = [0.512, 0.128, 0.128, 0.032, 0.2]\n        k = 100\n        self.multi_edge_loglik = <bound method Inference.multi_edge_loglik of <li...ood_calculations_shared_params.Inference object>>\n        aux_data = array([ 0.        ,  0.02874682,  0.0287428 ,  0.09696421])\n        obs_dict = {'lambda0': [0.46987360285665725], 'mu': array([ 0.27129109,  0.01121914,  1.11755202,  0.42456611]), 'n': 4, 'names': [('A_★', 'A_obs'), ('B_★', 'B_obs'), ('C_★', 'C_obs'), ('D_★', 'D_obs')], 'p': 0.8, 'psi': array([ 0.18512031,  0.00743781,  0.16059118,  0.04404889]), 'psi_shape': 1.0, 'r': array([ 0.68236785,  0.66295741,  0.14369906,  0.10375036]), 'r_shape': 1.0, 'scale_free_bounds': (0.01, 100)}\n        data_sets = None\n    176     \n    177 \n    178     def multi_edge_loglik(self, obs_data,aux_data,parameters):\n    179         # return np.sum([self.one_edge_loglik(aux_data[i+1],obs_data[i+1],parameters['psi'][i+1],parameters['r'][i+1]) for i in range(len(aux_data)-1)]) \n\nTypeError: 'NoneType' object is not iterable\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "result_graphs, result_posterior, result_loglik, result_dict = inference_obj.p_graph_given_d(graphs,config.options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_val = .05\n",
    "\n",
    "cond1 = [0,small_val,small_val,small_val]\n",
    "cond2 = [0,1,3,2]\n",
    "cond3 = [0,3,2,1]\n",
    "cond4 = [0,1,2,2]\n",
    "\n",
    "conds = np.array([cond1,cond2,cond3,cond4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05,  1.  ,  3.  ,  1.  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/graph_local_classes.py\u001b[0m(127)\u001b[0;36msubgraph_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    126 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 127 \u001b[0;31m        \u001b[0;32massert\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    128 \u001b[0;31m        \u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self\n",
      "<lib.graph_local_classes.GraphParams object at 0x1129449e8>\n",
      "ipdb> self.psi\n",
      "array([ 0.0346601 ,  0.29583947,  0.07826709,  0.11707177,  0.43367587,\n",
      "        1.47998856,  0.40990862,  0.15834476,  0.042935  ,  0.76834801,\n",
      "        0.03106284,  0.10213278,  0.00920209,  0.1237447 ,  0.51181212])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72c7d87e4ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_graph_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_graph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fix this when you can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmax_graph_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mblah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_loglik\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_graph_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/likelihood_calculations_shared_params.py\u001b[0m in \u001b[0;36msubgraph_loglik\u001b[0;34m(self, graph, max_graph_params, options)\u001b[0m\n\u001b[1;32m     84\u001b[0m             edge_types=[\"hidden_sample\"]))\n\u001b[1;32m     85\u001b[0m         gs_out = GraphStructure.from_networkx(sub_graph_from_edge_type(graph,\n\u001b[0;32m---> 86\u001b[0;31m             edge_types=[\"observed\"]))\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mgp_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_graph_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mgp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_graph_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/graph_local_classes.py\u001b[0m in \u001b[0;36msubgraph_copy\u001b[0;34m(self, edge_list)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mmatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_list_match_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cocosci/Dropbox/Work/Berkeley/Projects/Time/hidden_structure_inference/lib/graph_local_classes.py\u001b[0m in \u001b[0;36msubgraph_copy\u001b[0;34m(self, edge_list)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mmatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_list_match_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtmp_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.0/Frameworks/Python.framework/Versions/3.5/lib/python3.5/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_graph = graphs[0]\n",
    "num_graphs = len(graphs)\n",
    "num_params = config.options[\"param_sample_size\"]\n",
    "loglikelihood_by_param = np.zeros(shape = (num_params,num_graphs))\n",
    "max_graph_params = GraphParams.from_networkx(max_graph) # fix this when you can\n",
    "max_graph_params.sample()\n",
    "blah = inference_obj.subgraph_loglik(graphs[1],max_graph_params,options=config.options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.digraph.DiGraph at 0x1128d3dd8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3eb8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3ef0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3f28>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3f60>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3fd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6080>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e60b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e60f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6128>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e61d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6278>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e62b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e62e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6320>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6358>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6390>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e63c8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112878f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128745c0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874550>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874390>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874f28>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874710>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874400>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874470>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128746d8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874e80>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874cc0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874c18>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128742e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874908>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874da0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874860>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874a20>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128749e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128749b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874b00>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874fd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874b38>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874cf8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874b70>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874be0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874a90>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874c50>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874d30>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874438>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874e10>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874e48>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874f60>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874ba8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128746a0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128740f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874c88>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874358>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874d68>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874588>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874ef0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128744e0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874eb8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128741d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112874048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d34a8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3400>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3080>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d31d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d30b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d30f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3128>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3160>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3278>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d32b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d32e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d33c8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3320>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3390>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3358>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3470>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128d3438>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6160>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6400>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6438>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6470>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e64a8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e64e0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6550>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6518>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6588>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e65c0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e65f8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6630>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6668>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e66a0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e66d8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6710>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6748>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6780>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e67b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e67f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6828>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6860>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6898>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e68d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6908>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6940>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6978>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e69b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e69e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6a20>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6a58>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6a90>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6ac8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6b00>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6b38>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6b70>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6ba8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6be0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6c50>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6c18>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6c88>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6cc0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6cf8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6d68>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6d30>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6da0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6e10>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6dd8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6e48>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6e80>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6eb8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6ef0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6f60>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6f28>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1128e6fd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6080>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a60b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a60f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6128>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6160>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a61d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6278>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a62b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6320>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a62e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6358>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6390>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6400>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6438>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6470>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a63c8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a64a8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6518>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6550>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a64e0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6588>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a65c0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a65f8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6630>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6668>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a66a0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a66d8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6710>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6748>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a67b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6780>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6828>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a67f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6860>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6898>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a68d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6908>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6940>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6978>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a69b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a69e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6a20>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6a58>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6ac8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6a90>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6b00>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6b38>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6b70>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6ba8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6be0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6c18>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6c88>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6c50>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6cc0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6cf8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6d30>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6d68>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6da0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6dd8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6e10>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6e48>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6e80>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6eb8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6ef0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6f28>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6f60>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129a6fd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8080>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d80b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d80f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8128>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8160>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d81d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8278>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d82e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d82b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8320>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8358>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8390>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8400>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d83c8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8438>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8470>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d84a8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d84e0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8518>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8550>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d85c0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8588>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8630>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d85f8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8668>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d86a0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8710>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8748>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8780>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d87b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d87f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d86d8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8860>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8898>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8828>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d88d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8908>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8940>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8978>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d89b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d89e8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8a20>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8a90>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8a58>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8b00>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8ac8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8b38>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8b70>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8ba8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8c18>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8be0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8c50>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8c88>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8cc0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8cf8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8d30>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8d68>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8dd8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8da0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8e10>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8e48>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8e80>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8eb8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8ef0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8f28>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8f60>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8fd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09048>,\n",
       " <networkx.classes.digraph.DiGraph at 0x1129d8f98>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a090b8>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09080>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09128>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a090f0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09198>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a091d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09160>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09208>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a09240>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a092b0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x112a092e8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
